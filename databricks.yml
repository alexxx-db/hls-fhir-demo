# This is a Databricks asset bundle definition for hlsFHIRDemo.
# See https://docs.databricks.com/dev-tools/bundles/index.html for documentation.
bundle:
  name: hlsFHIRDemo
  uuid: a5226c0c-1dee-41da-8302-28250c1506f8

include:
  - resources/*.yml

targets:
  dev:
    # The default target uses 'mode: development' to create a development copy.
    # - Deployed resources get prefixed with '[dev my_user_name]'
    # - Any job schedules and triggers are paused by default.
    # See also https://docs.databricks.com/dev-tools/bundles/deployment-modes.html.
    mode: development
    default: true
    workspace:
      host: https://e2-demo-field-eng.cloud.databricks.com

  hls_webinar_fy25q4:
    mode: production
    workspace:
      host: https://adb-984752964297111.11.azuredatabricks.net/
      # We explicitly specify /Workspace/Users/matthew.giglia@databricks.com to make sure we only have a single copy.
      root_path: /Workspace/Users/${var.run_as_user}/.bundle/${bundle.name}/${bundle.target}
    permissions:
      - user_name: ${var.run_as_user}
        level: CAN_MANAGE
    run_as:
      user_name: ${var.run_as_user}
    variables:
      catalog_use: redox
      schema_use: hls_webinar_fy25q4
      workflow_name: hls_webinar_fy25q4_etl_pipeline

  prod:
    mode: production
    workspace:
      host: https://e2-demo-field-eng.cloud.databricks.com
      # We explicitly specify /Workspace/Users/matthew.giglia@databricks.com to make sure we only have a single copy.
      root_path: /Workspace/Users/${var.run_as_user}/.bundle/${bundle.name}/${bundle.target}
    permissions:
      - user_name: ${var.run_as_user}
        level: CAN_MANAGE
    run_as:
      user_name: ${var.run_as_user}

variables:
  catalog_use:
    default: fhir_workshop
    description: The Unity Catalog catalog that the schemas will be created in.  
  schema_use: 
    default: matthew_giglia
    description: The schema that will be created and used as part of the FHIR Workshop, or other demonstration code.  This schema will contain tables, volumes, SQL UDFs, and machine learning models. 
  workflow_name:
    default: fhir_etl_pipeline 
    description: The name of the FHIR ETL pipeline that will stream ingest FHIR JSON bundles from the landing volume and into bronze and then parse into a first level silver.  
  run_as_user: 
    default: matthew.giglia@databricks.com
    description: The user name, service principal or managed identity that the workflow should execute as.  Note that the development target will always run as the developer deploying to that target.   