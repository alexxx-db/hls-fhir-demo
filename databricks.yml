# This is a Databricks asset bundle definition for hlsFHIRDemo.
# See https://docs.databricks.com/dev-tools/bundles/index.html for documentation.
bundle:
  name: hlsFHIRDemo
  uuid: a5226c0c-1dee-41da-8302-28250c1506f8

include:
  # - resources/*.yml # Uncomment for demployments other than FHIR Ingestion Workshops
  - resources/workshop_lab_workspace_setup.job.yml
  - resources/workshop_synthea_fhir_ingestion.job.yml

targets:
  dev:
    # The default target uses 'mode: development' to create a development copy.
    # - Deployed resources get prefixed with '[dev my_user_name]'
    # - Any job schedules and triggers are paused by default.
    # See also https://docs.databricks.com/dev-tools/bundles/deployment-modes.html.
    mode: development
    default: true
    workspace:
      host: https://e2-demo-field-eng.cloud.databricks.com

  workshop:
    mode: production
    workspace:
      # edit the workshop url for the given Cloud Labs deployment
      host: https://dbc-857ff670-4c00.cloud.databricks.com/ 
      # We explicitly specify /Workspace/Users/matthew.giglia@databricks.com to make sure we only have a single copy.
      root_path: /Workspace/Users/${var.run_as_user}/.bundle/${bundle.name}/${bundle.target}
    permissions:
      - user_name: ${var.run_as_user}
        level: CAN_MANAGE
      - group_name: users
        level: CAN_VIEW
    run_as:
      user_name: ${var.run_as_user}
    variables:
      customer_name: WholeCare
      catalog_use: fhir_workshop
      schema_use: synthea
      workshop_fhir_ingestion_workflow_name: Synthea FHIR Ingestion
      workflow_trigger_pause_status: UNPAUSED
      # edit the run as user to be your instructor id 
      run_as_user: odl_instructor_1452233@databrickslabs.com
      sql_warehouse_id: b8e811181cae93c0

  hls_webinar_fy25q4:
    mode: production
    workspace:
      host: https://adb-984752964297111.11.azuredatabricks.net/
      # We explicitly specify /Workspace/Users/matthew.giglia@databricks.com to make sure we only have a single copy.
      root_path: /Workspace/Users/${var.run_as_user}/.bundle/${bundle.name}/${bundle.target}
    permissions:
      - user_name: ${var.run_as_user}
        level: CAN_MANAGE
    run_as:
      user_name: ${var.run_as_user}
    variables:
      catalog_use: redox
      schema_use: hls_webinar_fy25q4
      workflow_name: hls_webinar_fy25q4_etl_pipeline
      workflow_trigger_pause_status: UNPAUSED
      run_as_user: matthew.giglia@databricks.com
      sql_warehouse_id: 148ccb90800933a1

  himss25:
    mode: production
    workspace:
      host: https://e2-demo-field-events.cloud.databricks.com/
      # We explicitly specify /Workspace/Users/matthew.giglia@databricks.com to make sure we only have a single copy.
      root_path: /Workspace/Users/${var.run_as_user}/.bundle/${bundle.name}/${bundle.target}
    permissions:
      - user_name: ${var.run_as_user}
        level: CAN_MANAGE
    run_as:
      user_name: ${var.run_as_user}
    variables:
      catalog_use: redox
      schema_use: himss25
      workflow_name: redox_direct_etl_pipeline
      workflow_trigger_pause_status: UNPAUSED
      run_as_user: matthew.giglia@databricks.com
      sql_warehouse_id: 9cc108dc56e4efe9

  prod:
    mode: production
    workspace:
      host: https://e2-demo-field-eng.cloud.databricks.com
      # We explicitly specify /Workspace/Users/matthew.giglia@databricks.com to make sure we only have a single copy.
      root_path: /Workspace/Users/${var.run_as_user}/.bundle/${bundle.name}/${bundle.target}
    permissions:
      - user_name: ${var.run_as_user}
        level: CAN_MANAGE
    run_as:
      user_name: ${var.run_as_user}

variables:
  catalog_use:
    default: fhir_workshop
    description: The Unity Catalog catalog that the schemas will be created in.  
  schema_use: 
    default: matthew_giglia
    description: The schema that will be created and used as part of the FHIR Workshop, or other demonstration code.  This schema will contain tables, volumes, SQL UDFs, and machine learning models. 
  workflow_name:
    default: fhir_etl_pipeline 
    description: The name of the FHIR ETL pipeline that will stream ingest FHIR JSON bundles from the landing volume and into bronze and then parse into a first level silver.  
  workflow_trigger_pause_status:
    default: PAUSED
    description: Status of the workflow's file based trigger.  Switch to UNPAUSED for higher level environments.  
  run_as_user: 
    default: matthew.giglia@databricks.com
    description: The user name, service principal or managed identity that the workflow should execute as.  Note that the development target will always run as the developer deploying to that target. 
  sql_warehouse_id:
    default: 148ccb90800933a1
    description: The unique Databricks Serverless SQL Warehouse ID for SQL scoped notebooks to execute against.  Note that this is specific per workspace/host.   
  dev_tag: 
    default: matthew_giglia # odl_instructor_1452233@databrickslabs.com
    description: Automatica development tag for development targets.  
  full_refresh:
    default: false
    description: Boolean (evaluated as string when inputted as a parameter in a dbutils text widget) to perform a full refresh on all streaming tables.  
  customer_name:
    default: Databricks
    description: The name of the customer that is taking the workshop
  workshop_fhir_ingestion_workflow_name:
    default: Synthea FHIR Ingestion
    description: The name of the FHIR Ingestion workflow for the workshop








