```Note that this readme will be updated with run details for the Databricks Health & Life Science FY25 Q4 Interoperability Workshop shortly.  For now please find the demo notebooks in the "src" folder.  The workflow that was triggered from the Redox file arrival may be deployed as a Databricks Asset Bundle, with notebooks found in src/fhir-etl-pipeline.  The Prior Authorization Service Request FHIR Bundle loaded through the ELT pipeline and then reviewed in the demo notebooks can be found in fixtures.```  

```The notebooks contained in src/fhir_workshop were recently developed as part of a hands on 'CloudLabs course' where users will all build a streaming FHIR ETL pipeline together.  By the end of the four hour workshop you and your time will have stream ingested 1K FHIR JSONs and eith an AI/BI dashbord for insights.  Please contact your Databricks Account Team to learn more.```

# hlsFHIRDemo

<img src="media/Redox-Databricks Closed Loop.png" alt="Redox-Databricks Closed Loop" width="75%">

The 'hlsFHIRDemo' project was generated by using the default-python template.

## Getting started

1. Install the Databricks CLI from https://docs.databricks.com/dev-tools/cli/databricks-cli.html

2. Authenticate to your Databricks workspace, if you have not done so already:
    ```
    $ databricks configure
    ```

3. To deploy a development copy of this project, type:
    ```
    $ databricks bundle deploy --target dev
    ```
    (Note that "dev" is the default target, so the `--target` parameter
    is optional here.)

    This deploys everything that's defined for this project.
    For example, the default template would deploy a job called
    `[dev yourname] hlsFHIRDemo_job` to your workspace.
    You can find that job by opening your workpace and clicking on **Workflows**.

4. Similarly, to deploy a production copy, type:
   ```
   $ databricks bundle deploy --target prod
   ```

   Note that the default job from the template has a schedule that runs every day
   (defined in resources/hlsFHIRDemo.job.yml). The schedule
   is paused when deploying in development mode (see
   https://docs.databricks.com/dev-tools/bundles/deployment-modes.html).

5. To run a job or pipeline, use the "run" command:
   ```
   $ databricks bundle run
   ```

6. Optionally, install developer tools such as the Databricks extension for Visual Studio Code from
   https://docs.databricks.com/dev-tools/vscode-ext.html.

7. For documentation on the Databricks asset bundles format used
   for this project, and for CI/CD configuration, see
   https://docs.databricks.com/dev-tools/bundles/index.html.