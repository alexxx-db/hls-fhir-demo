{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "917f628e-36b6-451a-bea6-be2e81a886b2",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "_Note: This is a SQL scoped notebook, and therefore should be attached to a Serverless SQL warehouse for execution._  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "eb7643b7-88ea-4298-ab45-2da8c019e68b",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "# FHIR Workshop \n",
    "***\n",
    "\n",
    "#### Efficiently parsing FHIR JSON Bundles using Databricks SQL Serverless Streaming Tables and the Variant Data Type. \n",
    "\n",
    "\n",
    "## Unity Catalog Set Up\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "2baa5847-e7c5-4ac2-a5fa-32eabc19f611",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### Catalog Creation \n",
    "\n",
    "This workshop was designed so that multiple users could execute all commands including moving files, creating streaming tables or workflows at the same time in a classroom setting. The notebooks are written to take advantage of a single catalog that would be typically set up ahead of time, with each participant given all read/write or execute privileges.  Each user will end up creating a schema that is based on the their value from `current_user()` in Spark.  \n",
    "\n",
    "The below statement to create the catalog may be commented out and executed by the instructor or a member of the team with \"Create Catalog\" in the Unity Catalog metastore.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "0ec40eb3-b3de-49e9-9850-a36f8bddadf1",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "Create Catalog and Grant All Privileges to Account Users"
    }
   },
   "outputs": [],
   "source": [
    "-- CREATE CATALOG IF NOT EXISTS fhir_workshop;\n",
    "-- GRANT ALL PRIVILEGES ON CATALOG fhir_workshop TO `account users`;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "61667366-c92b-4840-9f1d-79f7a1bfcc71",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### Set Schema Value Using a SQL Declared Variable \n",
    "\n",
    "We can declare variables in SQL by using the `DECLARE OR REPLACE VARIABLE` snytax.  Here we specify that the schema that will be used based on the user's value of `current_user()` which is typically an email address.  We therefore split the value at the \"@\" symbol and replace any periods with underscores.  \n",
    "\n",
    "Since this will be same in each notebook we set the value of the declared variable using the `DEFAULT` syntax.  If we wanted to set the variable to a specific other value, we could use `SET VAR schema_use =` to do so.   We'll see this for another variable in a future notebook.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "6fa1e511-f8ca-466e-a54f-de54ec68ca85",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "Set the Schema to Use"
    }
   },
   "outputs": [],
   "source": [
    "DECLARE OR REPLACE VARIABLE schema_use STRING DEFAULT REPLACE(SPLIT(current_user(), '@')[0], '.', '_');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ba89f193-1c99-4494-909a-4279e56864a3",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "Select the Schema to Verify the Variable"
    }
   },
   "outputs": [],
   "source": [
    "SELECT schema_use;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "bd336c7a-48ef-4766-81e2-df894d07eb8a",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### Create the Schema in the fhir_workshop Catalog\n",
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "228b14a7-af99-47cf-8fec-064e1342b826",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "Use Catalog"
    }
   },
   "outputs": [],
   "source": [
    "USE CATALOG fhir_workshop;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "17369062-e4db-4e90-94f2-49101d5c354b",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "Create Schema in Default Catalog Managed Storage Location"
    }
   },
   "outputs": [],
   "source": [
    "CREATE SCHEMA IF NOT EXISTS IDENTIFIER(\"fhir_workshop.\" || schema_use);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d29e83c2-9799-48e2-9151-0f618609a337",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "When we need to call a Unity Catalog object such as a catalog, schema, table, function or model using a variable in SQL, we must wrap that variable with the `IDENTFIER` function to let the Spark SQL API know that we need the variable to explicitly evaluated before executing the rest of the statement.  Since `schema_use`is always going to be set by the start of our code we'll be seeing the `IDENTIFIER` frequently at the start of our SQL scoped notebooks.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "f0e79a13-9fc5-405a-9407-6d03502a4daa",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "Use Catalog.Schema Statement"
    }
   },
   "outputs": [],
   "source": [
    "USE IDENTIFIER(\"fhir_workshop.\" || schema_use);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "acf25269-2081-4c40-bb11-ed46f43f9a69",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "Its always a good idea to have the catalog and schema displayed at the top of a notebook, especially when the catalog or schema names are variable such as in a proper CI/CD environment.   \n",
    "\n",
    "Note that with Unity Catalog we refer to collections of governed assets inside a catalog as a schema, however for folks that were around for the original HDFS/Hive days we can still say \"database\" if we want to as well.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "212085c0-105a-4403-9c8d-d4dd64ec4b01",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "Display the current catalog and schema"
    }
   },
   "outputs": [],
   "source": [
    "SELECT\n",
    "  current_catalog()\n",
    "  ,current_schema()\n",
    "  ,current_database()\n",
    ";"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "72dd2e91-bb86-4388-9b38-375fd92ce5ae",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "053f66fc-b43c-47a8-b917-0ed960507a47",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "CREATE VOLUME IF NOT EXISTS landing;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e4d5d10b-ea61-4131-8689-4dcf4abbb670",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "SHOW VOLUMES;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e3faaa86-b9d4-47b3-a28d-49ee312a265b",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "-- LIST '/Volumes/fhir_workshop/synthea/synthetic_files_raw/output/fhir/' LIMIT 1000;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "17761e38-9911-4d04-98ff-82ebe840b38b",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "-- CREATE OR REPLACE FUNCTION copy_to_volume(\n",
    "--   source_volume STRING COMMENT \"The source volume path to copy the files from.\"\n",
    "--   ,target_volume STRING COMMENT \"The target volume path to move the files.\" \n",
    "--   ,file_pattern STRING COMMENT \"The file pattern to match using * for wild cards.\"\n",
    "-- )\n",
    "-- RETURNS STRING\n",
    "-- LANGUAGE PYTHON\n",
    "-- AS $$\n",
    "\n",
    "--   import subprocess\n",
    "\n",
    "--   # Check if the source and target volumes end with a slash\n",
    "--   if not source_volume.endswith('/'):\n",
    "--     source_volume += '/'\n",
    "\n",
    "--   if not target_volume.endswith('/'):\n",
    "--     target_volume += '/'\n",
    "\n",
    "--   # Use find to locate files based on the file pattern\n",
    "--   if file_pattern is None:\n",
    "--     file_pattern = '*'\n",
    "\n",
    "--   find_command = f\"find {source_volume} -name '{file_pattern}'\"\n",
    "--   files = subprocess.check_output(find_command, shell=True).decode().splitlines()\n",
    "\n",
    "--   # Copy each file to the destination directory\n",
    "--   for file in files:\n",
    "--       subprocess.run(['cp', file, target_volume])\n",
    "    \n",
    "--   return f\"Copied {str(len(files))} files.\"\n",
    "\n",
    "-- $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "9c0ea80f-1a1e-4ea5-a540-15258c1883a6",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "-- DROP FUNCTION copy_to_volume;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "bd0e1167-07b4-44b1-a997-0272ae1b564e",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "-- SELECT copy_to_volume(\n",
    "--   \"/Volumes/fhir_workshop/synthea/synthetic_files_raw/output/fhir/\"\n",
    "--   ,\"/Volumes/fhir_workshop/odl_instructor_1452233/landing/\"\n",
    "--   ,\"Aaron697*.json\"\n",
    "-- ) as copy_result;"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "client": "2"
   },
   "language": "sql",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "00 - Unity Catalog Setup",
   "widgets": {}
  },
  "language_info": {
   "name": "sql"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
