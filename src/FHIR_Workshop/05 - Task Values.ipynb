{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "6d297d76-556f-47be-a8a6-382a4d09b9c5",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "*Note that this notebook should be executed against Serverless Notebook or Job Compute*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "474124e1-f6b1-4b1f-b910-6148c23eeeed",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "# Using TaskValues to Dynamically Pass Information Between Tasks in a Databricks Workflow \n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "87cafe54-2990-49ed-b7e7-c3abfe7540ae",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Notebook Setup\n",
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "1024107e-68c5-49f9-bfed-6e6e8b072c7f",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "Set the Schema for the Notebook"
    }
   },
   "outputs": [],
   "source": [
    "schema_use = spark.sql(\"SELECT REPLACE(SPLIT(current_user(), '@')[0], '.', '_')\").collect()[0][0]\n",
    "schema_use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "41c2c8a8-94c1-457e-abfd-1974e8e753ef",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "Use the Catalog and Schema and Verify Its Set"
    }
   },
   "outputs": [],
   "source": [
    "spark.sql(f\"USE fhir_workshop.{schema_use}\")\n",
    "display(spark.sql(\"SELECT current_catalog(), current_database()\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "4d9a75ff-9d36-4f79-b200-46d1de7b5bd6",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Determine The Resource Types In Our System that Should Have Silver Tables\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "7f7faa32-0bfe-46dd-bb58-be712ea29562",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "Note that unlike other methods, this ensures we're not wasting compute on Resources we've never seen before, nor run the risk of missing a new Resource should it enter our system for the first time in a following refresh.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "632acfb4-c1d0-45f8-8760-953852bbe38c",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "Use SQL to Identify the Resource Types Available"
    }
   },
   "outputs": [],
   "source": [
    "resource_types = spark.sql(\"SELECT DISTINCT resourceType FROM fhir_resource_schemas\").collect()\n",
    "resource_types = [row.resourceType for row in resource_types]\n",
    "resource_types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "8862e8e0-70ed-4cdf-bfa6-ac91b24f6f27",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "This final step is the only reason its a Python Notebook and Not SQL"
    }
   },
   "outputs": [],
   "source": [
    "dbutils.jobs.taskValues.set(\"resource_types\", resource_types)"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "2"
   },
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "05 - Task Values",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
